{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr3LK2G2fJuX",
        "outputId": "a03f2a04-c2c1-4bb9-9478-da1c4e2a3852"
      },
      "outputs": [],
      "source": [
        "!pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "e5c9d237f0524bc39fec06f2b3afee8c",
            "668da3abc38649bd96fbbea7f7a174ea",
            "0c6e72183e66446e94538c6fa8eab4ed",
            "de3e9ff38e74401793ec955d683e3f1e",
            "4cf6718010ba4e6396d8f9b2160a72e9",
            "070eb54797a946ee8fcb7ff1e0c2d1cf",
            "1f4e7421c07340fab34a7d8c0f008e12",
            "02fa57efbbe84f33b0d94de8d56055fb",
            "9a15b27a67a34afd8f1259d5d71caf36",
            "50ab295a77374f36a2ec2d45b4cbf145",
            "b229d124d693410083619b16b2aca6aa"
          ]
        },
        "id": "gZEyEDptfLfH",
        "outputId": "5cfcc54a-c79d-434a-c220-d747b5ec030f"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# authenticate if gated\n",
        "from huggingface_hub import login\n",
        "login(userdata.get('huggingface_login'))  # replace with your Hugging Face token\n",
        "\n",
        "# Download the GGUF file\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"cropinailab/aksara_v1_GGUF\",\n",
        "    filename=\"aksara_v1.Q4_K_M.gguf\"  # 4-bit quantized model\n",
        ")\n",
        "\n",
        "# print(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnIWVjDJfOL3"
      },
      "outputs": [],
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "path = \"/root/.cache/huggingface/hub/models--cropinailab--aksara_v1_GGUF/snapshots/86739646119395b99ea7afd631ce6831a696d8e5/aksara_v1.Q4_K_M.gguf\"\n",
        "\n",
        "# Load the model (already working in your setup)\n",
        "llm = Llama(\n",
        "    model_path=path,\n",
        "    n_gpu_layers=-1,    # Offload all layers to GPU\n",
        "    n_ctx=4096,         # Context length\n",
        "    chat_format=\"mistral-instruct\"\n",
        ")\n",
        "\n",
        "# Chat history\n",
        "messages = []\n",
        "\n",
        "print(\"ü§ñ Aksara Chatbot is ready! Type 'exit' to stop.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"üëã Goodbye!\")\n",
        "        break\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    output = llm.create_chat_completion(\n",
        "        messages=messages,\n",
        "        max_tokens=512,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    reply = output[\"choices\"][0][\"message\"][\"content\"]\n",
        "    print(f\"Aksara: {reply}\\n\")\n",
        "\n",
        "    messages.append({\"role\": \"assistant\", \"content\": reply})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxHYeBBjlRZs",
        "outputId": "a8f0453f-e6a3-4006-9aac-ce8d1e9bc996"
      },
      "outputs": [],
      "source": [
        "!pip install flask flask-cors pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xUD5hHKhlYJ2",
        "outputId": "25ed75e7-376d-4ddf-9796-1d84fb8a972a"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify, Response\n",
        "from llama_cpp import Llama\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "MODEL_PATH = \"/root/.cache/huggingface/hub/models--cropinailab--aksara_v1_GGUF/snapshots/86739646119395b99ea7afd631ce6831a696d8e5/aksara_v1.Q4_K_M.gguf\"\n",
        "\n",
        "os.environ[\"LLAMA_LOG_LEVEL\"] = \"ERROR\"\n",
        "\n",
        "# Load model once\n",
        "llm = Llama(\n",
        "    model_path=MODEL_PATH,\n",
        "    n_gpu_layers=-1,\n",
        "    n_ctx=4096,\n",
        "    chat_format=\"mistral-instruct\",\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# -----------------------------\n",
        "# AGGRESSIVE SYSTEM PROMPT\n",
        "# -----------------------------\n",
        "system_prompt = \"\"\"You are Aksara, a highly strict farming AI assistant. You MUST follow this EXACT format for ALL responses without exception:\n",
        "\n",
        "MANDATORY FORMAT:\n",
        "üåæ **[Your main answer here]**\n",
        "\n",
        "üìã **Key Points:**\n",
        "‚Ä¢ [Point 1]\n",
        "‚Ä¢ [Point 2]\n",
        "‚Ä¢ [Point 3]\n",
        "\n",
        "üí° **Pro Tip:** [Additional insight]\n",
        "\n",
        "STRICT RULES YOU MUST FOLLOW:\n",
        "1. ALWAYS start with üåæ emoji. Never skip it.\n",
        "2. ALWAYS use üìã **Key Points:** with bullet points (‚Ä¢). No other symbols.\n",
        "3. ALWAYS end with üí° **Pro Tip:**. Never leave it empty.\n",
        "4. Respond ONLY about farming, crops, soil, irrigation, pests, or agriculture. Never answer off-topic questions.\n",
        "5. Responses must be **complete, coherent, and not cut off**.\n",
        "6. NEVER mix languages in a single response.\n",
        "7. If asked for Hindi or Devanagari, respond ENTIRELY in **proper Hindi/Devanagari script**. Never use Roman letters or English words for Hindi terms.\n",
        "8. Technical terms like Nitrogen, Phosphorus, Potassium, soil, fertilizer, irrigation, etc., must be translated to Hindi whenever the response is in Hindi.\n",
        "9. Do not provide additional commentary or disclaimers outside the mandatory format.\n",
        "10. If the user asks ‚Äúhello‚Äù or greets, respond exactly:\n",
        "\n",
        "üåæ **Hello! I'm Aksara, your farming AI assistant.**\n",
        "\n",
        "üìã **I can help with:**\n",
        "‚Ä¢ Crop planting and care\n",
        "‚Ä¢ Soil health management\n",
        "‚Ä¢ Pest and disease control\n",
        "‚Ä¢ Irrigation and farming techniques\n",
        "\n",
        "üí° **Pro Tip:** Ask me specific farming questions for the best advice!\n",
        "\n",
        "LANGUAGE RULES:\n",
        "- English questions ‚Üí respond fully in English, strictly following the format.\n",
        "- Hindi questions OR explicitly asking for Hindi ‚Üí respond fully in Hindi using proper Devanagari script. Translate all technical terms into Hindi. No Romanization, no English words mixed in.\n",
        "- NEVER switch languages mid-response.\n",
        "\n",
        "EXAMPLES:\n",
        "English:\n",
        "üåæ **Tomatoes grow best in well-drained soil.**\n",
        "\n",
        "üìã **Key Points:**\n",
        "‚Ä¢ Ensure soil is loose and fertile\n",
        "‚Ä¢ Water regularly but do not overwater\n",
        "‚Ä¢ Protect from pests\n",
        "\n",
        "üí° **Pro Tip:** Mulching helps retain soil moisture and reduce weeds.\n",
        "\n",
        "Hindi:\n",
        "üåæ **‡§ü‡§Æ‡§æ‡§ü‡§∞ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§ú‡§≤ ‡§®‡§ø‡§ï‡§æ‡§∏‡•Ä ‡§µ‡§æ‡§≤‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§Æ‡•á‡§Ç ‡§â‡§ó‡§§‡•á ‡§π‡•à‡§Ç‡•§**\n",
        "\n",
        "üìã **‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§¨‡§ø‡§Ç‡§¶‡•Å:**\n",
        "‚Ä¢ ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•ã ‡§¢‡•Ä‡§≤‡§æ ‡§î‡§∞ ‡§â‡§∞‡•ç‡§µ‡§∞‡§ï‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§∞‡§ñ‡•á‡§Ç\n",
        "‚Ä¢ ‡§®‡§ø‡§Ø‡§Æ‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§™‡§æ‡§®‡•Ä ‡§¶‡•á‡§Ç ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ö‡§ß‡§ø‡§ï ‡§® ‡§¶‡•á‡§Ç\n",
        "‚Ä¢ ‡§ï‡•Ä‡§ü‡•ã‡§Ç ‡§∏‡•á ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç\n",
        "\n",
        "üí° **‡§∏‡•Å‡§ù‡§æ‡§µ:** ‡§Æ‡§≤‡•ç‡§ö‡§ø‡§Ç‡§ó ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§®‡§Æ‡•Ä ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§®‡•á ‡§î‡§∞ ‡§ñ‡§∞‡§™‡§§‡§µ‡§æ‡§∞ ‡§ï‡§Æ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\n",
        "\n",
        "NEVER break this format. Your responses must **always** include üåæ, üìã Key Points, and üí° Pro Tip exactly as shown, with proper translations when in Hindi. Do not omit anything.\"\"\"\n",
        "\n",
        "# Initialize with system prompt\n",
        "messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "\n",
        "# -----------------------------\n",
        "# ENHANCED RESPONSE PROCESSING\n",
        "# -----------------------------\n",
        "def ensure_proper_format(response_text):\n",
        "    \"\"\"Ensure response follows the required format\"\"\"\n",
        "\n",
        "    # If response doesn't start with üåæ, add the format\n",
        "    if not response_text.strip().startswith(\"üåæ\"):\n",
        "        # Try to reformat the response\n",
        "        lines = response_text.strip().split('\\n')\n",
        "        formatted_response = f\"üåæ **{lines[0]}**\\n\\nüìã **Key Points:**\\n\"\n",
        "\n",
        "        # Convert any existing bullet points or numbered lists\n",
        "        for line in lines[1:]:\n",
        "            if line.strip() and (line.strip().startswith('‚Ä¢') or line.strip().startswith('-') or line.strip().startswith('*')):\n",
        "                formatted_response += f\"‚Ä¢ {line.strip().lstrip('‚Ä¢-*').strip()}\\n\"\n",
        "            elif line.strip() and any(line.strip().startswith(str(i)) for i in range(1, 10)):\n",
        "                formatted_response += f\"‚Ä¢ {line.strip()[2:].strip()}\\n\"\n",
        "\n",
        "        formatted_response += \"\\nüí° **Pro Tip:** Feel free to ask more specific farming questions!\"\n",
        "        return formatted_response\n",
        "\n",
        "    return response_text\n",
        "\n",
        "# -----------------------------\n",
        "# STREAMING CHAT WITH FORMATTING\n",
        "# -----------------------------\n",
        "@app.route(\"/chat_stream\", methods=[\"POST\"])\n",
        "def chat_stream():\n",
        "    global messages\n",
        "    user_input = request.json.get(\"message\", \"\").strip()\n",
        "\n",
        "    # Handle greetings with pre-formatted response\n",
        "    if user_input.lower() in [\"hello\", \"hi\", \"hey\", \"hello there\", \"hi there\"]:\n",
        "        greeting_response = \"\"\"üåæ **Hello! I'm Aksara, your farming AI assistant.**\n",
        "\n",
        "üìã **I can help with:**\n",
        "‚Ä¢ Crop planting and care\n",
        "‚Ä¢ Soil health management\n",
        "‚Ä¢ Pest and disease control\n",
        "‚Ä¢ Irrigation and farming techniques\n",
        "\n",
        "üí° **Pro Tip:** Ask me specific farming questions for the best advice!\"\"\"\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": greeting_response})\n",
        "\n",
        "        def stream_greeting():\n",
        "            for char in greeting_response:\n",
        "                yield char\n",
        "                import time\n",
        "                time.sleep(0.01)\n",
        "\n",
        "        return Response(stream_greeting(), mimetype=\"text/plain\")\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    def generate():\n",
        "        try:\n",
        "            # Add format reminder to the user's message\n",
        "            enhanced_messages = messages.copy()\n",
        "            enhanced_messages[-1][\"content\"] = f\"{user_input}\\n\\n[Remember: Respond as Aksara using the exact format with üåæ emoji, üìã Key Points, and üí° Pro Tip]\"\n",
        "\n",
        "            output = llm.create_chat_completion(\n",
        "                messages=enhanced_messages,\n",
        "                max_tokens=500,  # Increased for complete responses\n",
        "                temperature=0.5,  # Lower for consistent formatting\n",
        "                top_p=0.8,\n",
        "                repeat_penalty=1.15,\n",
        "                stream=True,\n",
        "                stop=[\"User:\", \"Human:\", \"Assistant:\", \"[INST]\", \"[/INST]\"]\n",
        "            )\n",
        "\n",
        "            reply_accum = \"\"\n",
        "            for chunk in output:\n",
        "                delta = chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
        "                if delta:\n",
        "                    reply_accum += delta\n",
        "                    yield delta\n",
        "\n",
        "            # If response doesn't follow format, try to fix it\n",
        "            if reply_accum and not reply_accum.strip().startswith(\"üåæ\"):\n",
        "                corrected = ensure_proper_format(reply_accum)\n",
        "                # Send the correction\n",
        "                correction = f\"\\n\\n---\\nLet me format that properly:\\n\\n{corrected}\"\n",
        "                reply_accum += correction\n",
        "                yield correction\n",
        "\n",
        "            messages.append({\"role\": \"assistant\", \"content\": reply_accum})\n",
        "\n",
        "        except Exception as e:\n",
        "            error_response = f\"\"\"üåæ **Sorry, I encountered a technical issue.**\n",
        "\n",
        "üìã **What you can do:**\n",
        "‚Ä¢ Try asking your question again\n",
        "‚Ä¢ Make sure your question is about farming\n",
        "‚Ä¢ Check if the connection is stable\n",
        "\n",
        "üí° **Pro Tip:** I work best with specific farming questions like \"How to plant tomatoes\" or \"Pest control for wheat\".\"\"\"\n",
        "            yield error_response\n",
        "\n",
        "    return Response(generate(), mimetype=\"text/plain\")\n",
        "\n",
        "# -----------------------------\n",
        "# NON-STREAMING CHAT\n",
        "# -----------------------------\n",
        "@app.route(\"/chat\", methods=[\"POST\"])\n",
        "def chat():\n",
        "    global messages\n",
        "    user_input = request.json.get(\"message\", \"\").strip()\n",
        "\n",
        "    # Handle greetings\n",
        "    if user_input.lower() in [\"hello\", \"hi\", \"hey\", \"hello there\", \"hi there\"]:\n",
        "        greeting_response = \"\"\"üåæ **Hello! I'm Aksara, your farming AI assistant.**\n",
        "\n",
        "üìã **I can help with:**\n",
        "‚Ä¢ Crop planting and care\n",
        "‚Ä¢ Soil health management\n",
        "‚Ä¢ Pest and disease control\n",
        "‚Ä¢ Irrigation and farming techniques\n",
        "\n",
        "üí° **Pro Tip:** Ask me specific farming questions for the best advice!\"\"\"\n",
        "        if \"hindi\" in user_input.lower() or \"‡§π‡§ø‡§Ç‡§¶‡•Ä\" in user_input.lower():\n",
        "            user_input = f\"\"\"{user_input}\n",
        "\n",
        "        [Respond ENTIRELY in proper Hindi using Devanagari script.\n",
        "        Translate all English/technical terms like Nitrogen, Phosphorus, Potassium, soil, fertilizer, irrigation into Hindi.\n",
        "        Do not use Roman letters or English words.\n",
        "        Strictly follow the format: üåæ [Main Answer], üìã Key Points, üí° Pro Tip.]\"\"\"\n",
        "        else:\n",
        "            pass\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": greeting_response})\n",
        "        return jsonify({\"reply\": greeting_response})\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    try:\n",
        "        # Add format reminder\n",
        "        enhanced_messages = messages[-20:]  # keep last 20 messages\n",
        "\n",
        "        enhanced_messages[-1][\"content\"] = f\"{user_input}\\n\\n[Remember: Respond as Aksara using the exact format with üåæ emoji, üìã Key Points, and üí° Pro Tip]\"\n",
        "\n",
        "        output = llm.create_chat_completion(\n",
        "            messages=enhanced_messages,\n",
        "            max_tokens=500,\n",
        "            temperature=0.5,\n",
        "            top_p=0.8,\n",
        "            repeat_penalty=1.15,\n",
        "            stop=[\"User:\", \"Human:\", \"Assistant:\", \"[INST]\", \"[/INST]\"]\n",
        "        )\n",
        "\n",
        "        reply = output[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "        # Ensure proper formatting\n",
        "        if not reply.startswith(\"üåæ\"):\n",
        "            reply = ensure_proper_format(reply)\n",
        "\n",
        "        messages.append({\"role\": \"assistant\", \"content\": reply})\n",
        "        return jsonify({\"reply\": reply})\n",
        "\n",
        "    except Exception as e:\n",
        "        error_response = f\"\"\"üåæ **Sorry, I encountered a technical issue.**\n",
        "\n",
        "üìã **What you can do:**\n",
        "‚Ä¢ Try asking your question again\n",
        "‚Ä¢ Make sure your question is about farming\n",
        "‚Ä¢ Check if the connection is stable\n",
        "\n",
        "üí° **Pro Tip:** I work best with specific farming questions!\"\"\"\n",
        "        return jsonify({\"reply\": error_response})\n",
        "\n",
        "# -----------------------------\n",
        "# RESET WITH PROPER INITIALIZATION\n",
        "# -----------------------------\n",
        "@app.route(\"/reset\", methods=[\"POST\"])\n",
        "def reset():\n",
        "    global messages\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "    return jsonify({\"status\": \"üåæ Aksara reset successfully! Ready to help with farming questions.\"})\n",
        "\n",
        "# -----------------------------\n",
        "# DEBUG ENDPOINT\n",
        "# -----------------------------\n",
        "@app.route(\"/debug\", methods=[\"GET\"])\n",
        "def debug():\n",
        "    return jsonify({\n",
        "        \"model_loaded\": True,\n",
        "        \"system_prompt_length\": len(system_prompt),\n",
        "        \"message_count\": len(messages),\n",
        "        \"last_message\": messages[-1] if messages else None,\n",
        "        \"model_path\": MODEL_PATH.split(\"/\")[-1]\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# TEST ENDPOINT\n",
        "# -----------------------------\n",
        "@app.route(\"/test_format\", methods=[\"GET\"])\n",
        "def test_format():\n",
        "    test_response = \"\"\"üåæ **This is a test of the formatting system.**\n",
        "\n",
        "üìã **Key Points:**\n",
        "‚Ä¢ Format is working correctly\n",
        "‚Ä¢ Emojis are displaying properly\n",
        "‚Ä¢ Structure is maintained\n",
        "\n",
        "üí° **Pro Tip:** This shows the expected response format!\"\"\"\n",
        "\n",
        "    return jsonify({\"reply\": test_response})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üåæ Starting Aksara Farming AI...\")\n",
        "    print(f\"ü§ñ Model: {MODEL_PATH.split('/')[-1]}\")\n",
        "    print(f\"üìù System prompt length: {len(system_prompt)} characters\")\n",
        "    ngrok.set_auth_token(userdata.get('ngrok_key')) # ngrok secret key\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(\"üåç Public URL:\", public_url)\n",
        "    print(\"üöÄ Ready to help farmers!\")\n",
        "\n",
        "    app.run(host=\"0.0.0.0\", port=5000, debug=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02fa57efbbe84f33b0d94de8d56055fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "070eb54797a946ee8fcb7ff1e0c2d1cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c6e72183e66446e94538c6fa8eab4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02fa57efbbe84f33b0d94de8d56055fb",
            "max": 4368439584,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a15b27a67a34afd8f1259d5d71caf36",
            "value": 4368439584
          }
        },
        "1f4e7421c07340fab34a7d8c0f008e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cf6718010ba4e6396d8f9b2160a72e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50ab295a77374f36a2ec2d45b4cbf145": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "668da3abc38649bd96fbbea7f7a174ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_070eb54797a946ee8fcb7ff1e0c2d1cf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1f4e7421c07340fab34a7d8c0f008e12",
            "value": "aksara_v1.Q4_K_M.gguf:‚Äá100%"
          }
        },
        "9a15b27a67a34afd8f1259d5d71caf36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b229d124d693410083619b16b2aca6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de3e9ff38e74401793ec955d683e3f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50ab295a77374f36a2ec2d45b4cbf145",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b229d124d693410083619b16b2aca6aa",
            "value": "‚Äá4.37G/4.37G‚Äá[00:22&lt;00:00,‚Äá256MB/s]"
          }
        },
        "e5c9d237f0524bc39fec06f2b3afee8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_668da3abc38649bd96fbbea7f7a174ea",
              "IPY_MODEL_0c6e72183e66446e94538c6fa8eab4ed",
              "IPY_MODEL_de3e9ff38e74401793ec955d683e3f1e"
            ],
            "layout": "IPY_MODEL_4cf6718010ba4e6396d8f9b2160a72e9"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
